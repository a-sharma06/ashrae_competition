{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Concatenate, Flatten, Reshape, Lambda\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, LSTM\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"gs://123test_bucket/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling by np.log1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['meter_reading'] = np.log1p(train['meter_reading'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying TimeseriesGenerator to the ASHRAE training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once difference between the example above, and our situation is that we have multiple timeseries, for each building and each meter in the building. So, we will be required to modify the code a little bit.\n",
    "\n",
    "Below, we check how many meters exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2380"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[['building_id', 'meter']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below has been taken from this stackoverflow answer with some modifications:\n",
    "https://stackoverflow.com/questions/55116638/use-keras-timeseriesgenerator-function-to-generate-squence-group-by-some-id/55118459#55118459\n",
    "\n",
    "The modification is basically that once we subset the data for building ID, it is then subset for meter type also.\n",
    "\n",
    "Further reading about modifying keras generator classes can be found below:\n",
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20216108"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TimeseriesGenerator(train.meter_reading.values,train.meter_reading.values,168,batch_size=10))*10 + 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20216100"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/55116638/use-keras-timeseriesgenerator-function-to-generate-squence-group-by-some-id/55118459#55118459\n",
    "# https://keras.io/preprocessing/sequence/\n",
    "class TSDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, dt, length = 168, batch_size = 10):\n",
    "        self.tgs = list()\n",
    "        self.count = 0\n",
    "\n",
    "        for i in range(dt['building_id'].min(),dt['building_id'].max()+1):\n",
    "            sub = dt.loc[dt['building_id'] == i, ['meter', 'meter_reading']]\n",
    "            for meter in sub['meter'].unique():\n",
    "                # subsetting sub for meter type\n",
    "                adf = sub.loc[sub['meter'] == meter, 'meter_reading'].values\n",
    "                adf = np.reshape(adf, (len(adf),1))\n",
    "                self.tgs.append(TimeseriesGenerator(adf,adf,length,batch_size=batch_size))\n",
    "                \n",
    "                l = np.ceil((len(adf) - length)/batch_size)              \n",
    "                self.count = self.count+l             \n",
    "#                 if (len(TimeseriesGenerator(adf,adf,length,batch_size=batch_size))-l != 0):\n",
    "#                     print(len(TimeseriesGenerator(adf,adf,length,batch_size=batch_size)), len(adf), l)\n",
    "        self.len = sum([len(tg) for tg in self.tgs])\n",
    "        self.idx_i = list()\n",
    "        self.idx_j = list()\n",
    "\n",
    "        for i, tg in enumerate(self.tgs):\n",
    "            self.idx_i.extend(list(range(len(tg))))\n",
    "            self.idx_j.extend([i]*len(tg))    \n",
    "        #print ( self.idx_i,  self.idx_j)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tgs[self.idx_j[index]][self.idx_i[index]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrdinalEncoder(categories='auto', dtype=<class 'numpy.float64'>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = OrdinalEncoder()\n",
    "enc.fit(train[['building_id', 'meter']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[1.],\n",
       "        [0.]]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(train[['building_id', 'meter']])[0:2].reshape(2,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, dt, length = 168, batch_size = 10):\n",
    "        self.batch_size = batch_size\n",
    "        self.tgs = list()\n",
    "        self.count = 0\n",
    "        for i in range(dt['building_id'].min(),dt['building_id'].max()+1):\n",
    "            sub = dt.loc[dt['building_id'] == i, ['building_id', 'meter']]\n",
    "            for meter in sub['meter'].unique():\n",
    "                adf = sub.loc[sub['meter'] == meter, ['building_id', 'meter']]\n",
    "                # No. of columns\n",
    "                cols = len(adf.columns)\n",
    "                \n",
    "                # Converting to categorical\n",
    "                tm = enc.transform(adf[['building_id', 'meter']])\n",
    "                \n",
    "                # How many batches \n",
    "                l = np.ceil((len(adf) - length)/batch_size)\n",
    "                self.count = self.count+l\n",
    "                l = int(l)\n",
    "                # For each batch, the X, Y are generated\n",
    "                for j in range(l):\n",
    "                    index_start = batch_size*length\n",
    "                    index_end = (batch_size+1)*length\n",
    "                    cat = tm[index_start, index_end]\n",
    "                    \n",
    "                    x = cat.reshape(len(cat),cols,1)\n",
    "                    y = np.zeros((len(cat),1))\n",
    "                    self.tgs.append((x,y))\n",
    "                \n",
    "        self.len = self.count\n",
    "        #print(self.len)\n",
    "        self.idx_i = list()\n",
    "        self.idx_j = list()\n",
    "\n",
    "        for i, tg in enumerate(self.tgs):\n",
    "            self.idx_i.extend(list(range(len(tg))))\n",
    "            self.idx_j.extend([i]*len(tg))    \n",
    "        #print ( self.idx_i,  self.idx_j)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tgs[index*self.batch_size:(index+1)*self.batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on a manual check it was found that there were 12 unique meters in the train_sub dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we want to use 24*7 timesteps, representing 7 days and 24 hours. We can experiment with the batch size but using 20 here for a short example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Validation Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 30% of the data as validation data. If more data is needed, we should consider adding data by randomly selecting buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = train['building_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only 5% of the ids\n",
    "len_sub = round(len(ids)*0.05)\n",
    "ids_sub = np.random.choice(ids, len_sub, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.3 represents the percentage of data that is kept for validation\n",
    "len_val = round(len(ids_sub)*0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_val = np.random.choice(ids_sub, len_val, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train = np.setdiff1d(ids_sub,ids_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(ids_val)+len(ids_train)==len(ids_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1548288"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1536*6*168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building_id  meter\n",
       "0            0        4392.0\n",
       "1            0        4392.0\n",
       "2            0        4392.0\n",
       "3            0        4392.0\n",
       "4            0        4392.0\n",
       "5            0        4392.0\n",
       "6            0        4392.0\n",
       "7            0        4392.0\n",
       "             1        3633.5\n",
       "8            0        4392.0\n",
       "Name: meter_reading, dtype: float64"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['building_id', 'meter'])['meter_reading'].count().head(10)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "length = 24*7\n",
    "batch_size = 1024+512\n",
    "train_gen = TSDataGenerator(train[train['building_id'].isin(ids_train)],length, batch_size = batch_size)\n",
    "val_gen = TSDataGenerator(train[train['building_id'].isin(ids_val)],length, batch_size = batch_size)\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478 478.0\n",
      "235 235.0\n"
     ]
    }
   ],
   "source": [
    "print(train_gen.len, train_gen.count)\n",
    "print(val_gen.len, val_gen.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 258048 is out of bounds for axis 0 with size 8784",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-442-e9907558de2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain2_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCatDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'building_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-441-cf03960e57ac>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dt, length, batch_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mindex_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mindex_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                     \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 258048 is out of bounds for axis 0 with size 8784"
     ]
    }
   ],
   "source": [
    "train2_gen = CatDataGenerator(train[train['building_id'].isin(ids_train)],length, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 478.0)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.len, train2_gen.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478.0, 478.0)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen.count, train2_gen.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1160, 168, 1)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen[477][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 2, 1)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2_gen[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train2_gen.tgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-1D Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 168)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch_size,1,length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN 1-D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "filters = 10\n",
    "input_shape = Input(shape=(length,1))\n",
    "\n",
    "m1 = Conv1D(filters=filters, kernel_size=3, activation='relu')(input_shape)\n",
    "m1 = MaxPooling1D(pool_size=2, strides=2)(m1)\n",
    "\n",
    "#m2 = Conv1D(filters=filters, kernel_size=5, activation='relu')(input_shape)\n",
    "#m2 = MaxPooling1D(pool_size=2, strides=2)(m2)\n",
    "\n",
    "#m3 = Conv1D(filters=filters, kernel_size=7, activation='relu')(input_shape)\n",
    "#m3 = MaxPooling1D(pool_size=2, strides=2)(m3)\n",
    "\n",
    "#m = keras.layers.concatenate([m1, m2, m3], axis = 1)\n",
    "#m = Reshape((246,filters))(m)\n",
    "m = LSTM(64, return_sequences=True)(m1)\n",
    "m = Lambda(lambda x: keras.backend.mean(x, axis=2))(m)\n",
    "\n",
    "out = Dense(24, activation='relu')(m)\n",
    "out = Dense(1, activation='relu')(out)\n",
    "\n",
    "model = Model(input_shape, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=root_mean_squared_error, optimizer='rmsprop', metrics=['mse', 'mae', 'mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 168, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 166, 10)           40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 83, 10)            0         \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 83, 64)            19200     \n",
      "_________________________________________________________________\n",
      "lambda_17 (Lambda)           (None, 83)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 24)                2016      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 21,281\n",
      "Trainable params: 21,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "442/537 [=======================>......] - ETA: 2:36 - loss: 439.4151 - mse: 2496411.7500 - mae: 357.4307 - mape: 1241150720.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-962:\n",
      "Process ForkPoolWorker-961:\n",
      "Process ForkPoolWorker-960:\n",
      "Process ForkPoolWorker-956:\n",
      "Process ForkPoolWorker-963:\n",
      "Process ForkPoolWorker-957:\n",
      "Process ForkPoolWorker-954:\n",
      "Process ForkPoolWorker-955:\n",
      "Process ForkPoolWorker-952:\n",
      "Process ForkPoolWorker-958:\n",
      "Process ForkPoolWorker-965:\n",
      "Process ForkPoolWorker-944:\n",
      "Process ForkPoolWorker-959:\n",
      "Process ForkPoolWorker-942:\n",
      "Process ForkPoolWorker-945:\n",
      "Process ForkPoolWorker-947:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-951:\n",
      "Process ForkPoolWorker-953:\n",
      "Process ForkPoolWorker-950:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-964:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-943:\n",
      "Process ForkPoolWorker-946:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-949:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-948:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-7d864f887ff9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     workers=12)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model on dataset\n",
    "model.fit_generator(generator=train_gen,\n",
    "                    validation_data=val_gen, epochs=5,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=12)\n",
    "# Add input for building id, and join it with lamda output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
