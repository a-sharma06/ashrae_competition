{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Concatenate, Flatten, Reshape, Lambda\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, LSTM\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpful links:\n",
    "1. Inverse of np.log1p: https://stackoverflow.com/questions/50049891/what-is-the-inverse-of-numpys-log1p\n",
    "2. Building parallel keras model: https://stackoverflow.com/questions/43151775/how-to-have-parallel-convolutional-layers-in-keras\n",
    "3. How to make parallel keras models: https://datascience.stackexchange.com/questions/39407/how-to-make-two-parallel-convolutional-neural-networks-in-keras\n",
    "4. 2 parallel keras layers: https://stackoverflow.com/questions/51546075/two-parallel-conv2d-layers-keras\n",
    "5. Setting up Conv1D and LSTM: https://stackoverflow.com/questions/51344610/how-to-setup-1d-convolution-and-lstm-in-keras\n",
    "6. Take average of LSTM hidden states using Lambda: https://stackoverflow.com/questions/51479940/average-channels-of-convolutional-layer-keras\n",
    "7. Preparing categorical variable for neural networks: https://machinelearningmastery.com/how-to-prepare-categorical-data-for-deep-learning-in-python/\n",
    "8. Tutorial for using keras for time series (no generators used): https://medium.com/@jdwittenauer/deep-learning-with-keras-structured-time-series-37a66c6aeb28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"gs://123test_bucket/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.timestamp = pd.to_datetime(train.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['month'] = train.timestamp.dt.month\n",
    "train['dayofweek'] = train.timestamp.dt.dayofweek\n",
    "train['hour'] = train.timestamp.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20216100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 30% of the data as validation data. If more data is needed, we should consider adding data by randomly selecting buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = train['building_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only 5% of the ids\n",
    "len_sub = round(len(ids)*0.05)\n",
    "ids_sub = np.random.choice(ids, len_sub, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.3 represents the percentage of data that is kept for validation\n",
    "len_val = round(len(ids_sub)*0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_val = np.random.choice(ids_sub, len_val, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train = np.setdiff1d(ids_sub,ids_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(ids_val)+len(ids_train)==len(ids_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling by np.log1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['meter_reading'] = np.log1p(train['meter_reading'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying TimeseriesGenerator to the ASHRAE training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once difference between the example above, and our situation is that we have multiple timeseries, for each building and each meter in the building. So, we will be required to modify the code a little bit.\n",
    "\n",
    "Below, we check how many meters exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2380"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[['building_id', 'meter']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below has been taken from this stackoverflow answer with some modifications:\n",
    "https://stackoverflow.com/questions/55116638/use-keras-timeseriesgenerator-function-to-generate-squence-group-by-some-id/55118459#55118459\n",
    "\n",
    "The modification is basically that once we subset the data for building ID, it is then subset for meter type also.\n",
    "\n",
    "Further reading about modifying keras generator classes can be found below:\n",
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrdinalEncoder(categories='auto', dtype=<class 'numpy.float64'>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['building_id', 'meter', 'hour', 'dayofweek', 'month']\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(train[col_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/55116638/use-keras-timeseriesgenerator-function-to-generate-squence-group-by-some-id/55118459#55118459\n",
    "# https://keras.io/preprocessing/sequence/\n",
    "# https://stackoverflow.com/questions/49404993/keras-how-to-use-fit-generator-with-multiple-inputs/49405175\n",
    "# https://medium.com/datadriveninvestor/keras-training-on-large-datasets-3e9d9dbc09d4\n",
    "class TSDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, dt, length = 168, batch_size = 10):\n",
    "        self.tgs = list()\n",
    "        self.count = 0 # counter: for verifying the length\n",
    "        # counting batches this way is needed for calculating\n",
    "        # batches for categorical data\n",
    "        \n",
    "        # for each building_id, and meter create batches of time series\n",
    "        for i in range(dt['building_id'].min(),dt['building_id'].max()+1):\n",
    "            sub = dt.loc[dt['building_id'] == i, ['meter', 'meter_reading']]\n",
    "            \n",
    "            for meter in sub['meter'].unique():\n",
    "                # subsetting for meter type\n",
    "                adf = sub.loc[sub['meter'] == meter, 'meter_reading'].values\n",
    "                # the data needs to be reformatted so that it fits the neural \n",
    "                # network model properly\n",
    "                adf = np.reshape(adf, (len(adf),1))\n",
    "                \n",
    "                # adding the timeseriesgenerator to a list of batches\n",
    "                self.tgs.append(TimeseriesGenerator(adf,adf,length,batch_size=batch_size))\n",
    "                \n",
    "                # calculating length\n",
    "                l = np.ceil((len(adf) - length)/batch_size)              \n",
    "                self.count = self.count+l             \n",
    "\n",
    "        self.len = sum([len(tg) for tg in self.tgs])\n",
    "        self.idx_i = list()\n",
    "        self.idx_j = list()\n",
    "\n",
    "        for i, tg in enumerate(self.tgs):\n",
    "            self.idx_i.extend(list(range(len(tg))))\n",
    "            self.idx_j.extend([i]*len(tg))    \n",
    "        #print ( self.idx_i,  self.idx_j)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tgs[self.idx_j[index]][self.idx_i[index]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, dt, length = 168, batch_size = 10):\n",
    "        self.batch_size = batch_size\n",
    "        self.tgs = list()\n",
    "        self.count = 0\n",
    "        col_names = ['building_id', 'meter', 'hour', 'dayofweek', 'month']\n",
    "        for i in range(dt['building_id'].min(),dt['building_id'].max()+1):\n",
    "            sub = dt.loc[dt['building_id'] == i, col_names]\n",
    "            for meter in sub['meter'].unique():\n",
    "                # subsetting the building_id, and meter\n",
    "                adf = sub.loc[sub['meter'] == meter, col_names].copy().reset_index(drop=True)\n",
    "                # number of columns\n",
    "                cols = len(adf.columns)\n",
    "                \n",
    "                # Encoding categorical data\n",
    "                tm = enc.transform(adf[col_names])\n",
    "                tm_short = tm[length:]\n",
    "                \n",
    "                # How many batches \n",
    "                l = np.ceil((len(adf) - length)/batch_size)\n",
    "                self.count = self.count+l\n",
    "                l = int(l)\n",
    "\n",
    "                for j in range(l):\n",
    "                    # correctly indexing the series,\n",
    "                    # this ensures the length is correct\n",
    "                    index_start = j*batch_size\n",
    "                    index_end = index_start+batch_size\n",
    "                    cat = tm_short[index_start:index_end] \n",
    "                    \n",
    "                    # we select the value after the index_end,\n",
    "                    # corresponding to y.\n",
    "                    #val = tm[(index_end+1)] \n",
    "                    size = len(cat)\n",
    "                    #print(val)\n",
    "                    # reshaping the data\n",
    "                    x = cat#.reshape((size,1))\n",
    "                    y = np.zeros((size,1))\n",
    "                    self.tgs.append((x,y))\n",
    "                \n",
    "        self.len = self.count\n",
    "        self.idx_i = list()\n",
    "        self.idx_j = list()\n",
    "\n",
    "        for i, tg in enumerate(self.tgs):\n",
    "            self.idx_i.extend(list(range(len(tg))))\n",
    "            self.idx_j.extend([i]*len(tg))    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tgs[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleInputGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, dt, length = 168, batch_size = 10):\n",
    "        self.train1_gen = TSDataGenerator(dt,length, batch_size = batch_size)\n",
    "        self.train2_gen = CatDataGenerator(dt,length, batch_size = batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"It is mandatory to implement it on Keras Sequence\"\"\"\n",
    "        if self.train1_gen.__len__() == self.train2_gen.__len__():\n",
    "            return self.train1_gen.__len__()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Getting items from the 2 generators and packing them\"\"\"\n",
    "        X1_batch, Y1_batch = self.train1_gen.__getitem__(index)\n",
    "        X2_batch, Y2_batch = self.train2_gen.__getitem__(index)\n",
    "\n",
    "        X_batch = [X1_batch, X2_batch]\n",
    "\n",
    "        return X_batch, Y1_batch    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on a manual check it was found that there were 12 unique meters in the train_sub dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we want to use 24*7 timesteps, representing 7 days and 24 hours. We can experiment with the batch size but using 20 here for a short example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Validation Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "length = 24*7\n",
    "batch_size = 1024+512\n",
    "train_gen = MultipleInputGenerator(train[train['building_id'].isin(ids_train)],length, batch_size = batch_size)\n",
    "val_gen = MultipleInputGenerator(train[train['building_id'].isin(ids_val)],length, batch_size = batch_size)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the row counts match\n",
    "check = list()\n",
    "for i in range(len(train_gen)):\n",
    "    check.append((train_gen[i][0][1][0][0],train_gen[i][0][1][0][1], train_gen[i][0][0].shape[0]))\n",
    "    if not train_gen[i][0][0].shape[0]==train_gen[i][0][1].shape[0]==train_gen[i][1].shape[0]:\n",
    "        print(train_gen[i][0][0].shape[0],train_gen[i][0][1].shape[0],train_gen[i][1].shape[0], \n",
    "              i, train_gen[i][0][1][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536, 168, 1) (1536, 5) (1536, 1)\n"
     ]
    }
   ],
   "source": [
    "check = train_gen[0]\n",
    "print(check[0][0].shape, check[0][1].shape, check[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = train[(train['building_id'] == 5) & (train['meter'] == 0) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>386012</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-08 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388305</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-08 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390597</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-08 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392891</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-08 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395188</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-08 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3747264</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-11 19:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3749375</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-11 20:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3751484</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-11 21:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3753592</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-11 22:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3755700</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-03-11 23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1536 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         building_id  meter           timestamp  meter_reading  month  \\\n",
       "386012             5      0 2016-01-08 00:00:00            0.0      1   \n",
       "388305             5      0 2016-01-08 01:00:00            0.0      1   \n",
       "390597             5      0 2016-01-08 02:00:00            0.0      1   \n",
       "392891             5      0 2016-01-08 03:00:00            0.0      1   \n",
       "395188             5      0 2016-01-08 04:00:00            0.0      1   \n",
       "...              ...    ...                 ...            ...    ...   \n",
       "3747264            5      0 2016-03-11 19:00:00            0.0      3   \n",
       "3749375            5      0 2016-03-11 20:00:00            0.0      3   \n",
       "3751484            5      0 2016-03-11 21:00:00            0.0      3   \n",
       "3753592            5      0 2016-03-11 22:00:00            0.0      3   \n",
       "3755700            5      0 2016-03-11 23:00:00            0.0      3   \n",
       "\n",
       "         dayofweek  hour  \n",
       "386012           4     0  \n",
       "388305           4     1  \n",
       "390597           4     2  \n",
       "392891           4     3  \n",
       "395188           4     4  \n",
       "...            ...   ...  \n",
       "3747264          4    19  \n",
       "3749375          4    20  \n",
       "3751484          4    21  \n",
       "3753592          4    22  \n",
       "3755700          4    23  \n",
       "\n",
       "[1536 rows x 7 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[length:(length+batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  0.,  0.,  4.,  0.],\n",
       "       [ 5.,  0.,  1.,  4.,  0.],\n",
       "       [ 5.,  0.,  2.,  4.,  0.],\n",
       "       ...,\n",
       "       [ 5.,  0., 21.,  4.,  2.],\n",
       "       [ 5.,  0., 22.,  4.,  2.],\n",
       "       [ 5.,  0., 23.,  4.,  2.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-1D Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536, 1, 168)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch_size,1,length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN 1-D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "filters = 10\n",
    "ncols = len(col_names) # categorical columns\n",
    "states = 24\n",
    "input_shape1 = Input(shape=(length,1))\n",
    "input_shape2 = Input(shape=(ncols,))\n",
    "\n",
    "m1 = Conv1D(filters=filters, kernel_size=3, activation='relu')(input_shape1)\n",
    "m1 = MaxPooling1D(pool_size=2, strides=2)(m1)\n",
    "\n",
    "#m2 = Conv1D(filters=filters, kernel_size=5, activation='relu')(input_shape1)\n",
    "#m2 = MaxPooling1D(pool_size=2, strides=2)(m2)\n",
    "\n",
    "#m3 = Conv1D(filters=filters, kernel_size=7, activation='relu')(input_shape1)\n",
    "#m3 = MaxPooling1D(pool_size=2, strides=2)(m3)\n",
    "\n",
    "#m = keras.layers.concatenate([m1, m2, m3], axis = 1)\n",
    "#m = Reshape((246,filters))(m)\n",
    "m_a = LSTM(states, return_sequences=True)(m1)\n",
    "m_a = Lambda(lambda x: keras.backend.mean(x, axis=2))(m_a)\n",
    "m_a = Model(inputs=input_shape1, outputs=m_a)\n",
    "\n",
    "#m_b = Dense(2, activation='relu')(input_shape2)\n",
    "#m_b = Model(inputs=input_shape2, outputs=m_b)\n",
    "\n",
    "#combined = keras.layers.concatenate([m_a.output, m_b.output])\n",
    "combined = keras.layers.concatenate([m_a.output, input_shape2])\n",
    "\n",
    "out = Dense(states, activation='relu')(combined)\n",
    "out = Dense(1, activation='relu')(out)\n",
    "\n",
    "model = Model(inputs = [input_shape1, input_shape2], outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=root_mean_squared_error, optimizer='rmsprop', metrics=['mse', 'mae', 'mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 168, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 166, 10)      40          input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 83, 10)       0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (None, 83, 24)       3360        max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 83)           0           lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 88)           0           lambda_9[0][0]                   \n",
      "                                                                 input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 24)           2136        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1)            25          dense_20[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 5,561\n",
      "Trainable params: 5,561\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "217/521 [===========>..................] - ETA: 5:15 - loss: nan - mse: nan - mae: nan - mape: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-287:\n",
      "Process ForkPoolWorker-285:\n",
      "Process ForkPoolWorker-284:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-289:\n",
      "Process ForkPoolWorker-282:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-283:\n",
      "Process ForkPoolWorker-280:\n",
      "Process ForkPoolWorker-278:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-277:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-276:\n",
      "Process ForkPoolWorker-275:\n",
      "Process ForkPoolWorker-279:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-281:\n",
      "Process ForkPoolWorker-270:\n",
      "Process ForkPoolWorker-272:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-269:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-266:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "Process ForkPoolWorker-274:\n",
      "Process ForkPoolWorker-286:\n",
      "Process ForkPoolWorker-273:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-267:\n",
      "Process ForkPoolWorker-271:\n",
      "Process ForkPoolWorker-268:\n",
      "Process ForkPoolWorker-288:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-2a19e9404fa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     workers=12)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Add input for building id, and join it with lamda output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model on dataset\n",
    "model.fit_generator(generator=train_gen,\n",
    "                    validation_data=val_gen, epochs=5,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=12)\n",
    "# Add input for building id, and join it with lamda output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
