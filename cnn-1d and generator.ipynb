{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, LeakyReLU\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Concatenate, Flatten, Reshape, Lambda\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, LSTM\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpful links:\n",
    "1. Inverse of np.log1p: https://stackoverflow.com/questions/50049891/what-is-the-inverse-of-numpys-log1p\n",
    "2. Building parallel keras model: https://stackoverflow.com/questions/43151775/how-to-have-parallel-convolutional-layers-in-keras\n",
    "3. How to make parallel keras models: https://datascience.stackexchange.com/questions/39407/how-to-make-two-parallel-convolutional-neural-networks-in-keras\n",
    "4. 2 parallel keras layers: https://stackoverflow.com/questions/51546075/two-parallel-conv2d-layers-keras\n",
    "5. Setting up Conv1D and LSTM: https://stackoverflow.com/questions/51344610/how-to-setup-1d-convolution-and-lstm-in-keras\n",
    "6. Take average of LSTM hidden states using Lambda: https://stackoverflow.com/questions/51479940/average-channels-of-convolutional-layer-keras\n",
    "7. Preparing categorical variable for neural networks: https://machinelearningmastery.com/how-to-prepare-categorical-data-for-deep-learning-in-python/\n",
    "8. Tutorial for using keras for time series (no generators used): https://medium.com/@jdwittenauer/deep-learning-with-keras-structured-time-series-37a66c6aeb28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"gs://123test_bucket/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading = train['meter_reading']\n",
    "train['meter_reading'] = np.log1p(train['meter_reading'])\n",
    "train['meter_reading'] = MinMaxScaler().fit_transform(X=np.reshape(train['meter_reading'].values, (-1, 1))).reshape(len(train),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2452794762030242"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['meter_reading'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"gs://123test_bucket/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining Month, Day of the Week, and Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.timestamp = pd.to_datetime(train.timestamp)\n",
    "\n",
    "test.timestamp = pd.to_datetime(test.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['month'] = train.timestamp.dt.month\n",
    "train['dayofweek'] = train.timestamp.dt.dayofweek\n",
    "train['hour'] = train.timestamp.dt.hour\n",
    "\n",
    "test['month'] = test.timestamp.dt.month\n",
    "test['dayofweek'] = test.timestamp.dt.dayofweek\n",
    "test['hour'] = test.timestamp.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20216100, 41697600)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 30% of the data as validation data. If more data is needed, we should consider adding data by randomly selecting buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = train['building_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only 5% of the ids\n",
    "len_sub = round(len(ids)*0.05)\n",
    "ids_sub = np.random.choice(ids, len_sub, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.3 represents the percentage of data that is kept for validation\n",
    "len_val = round(len(ids_sub)*0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_val = np.random.choice(ids_sub, len_val, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_train = np.setdiff1d(ids_sub,ids_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(ids_val)+len(ids_train)==len(ids_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling by np.log1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['meter_reading'] = np.log1p(train['meter_reading'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying TimeseriesGenerator to the ASHRAE training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once difference between the example above, and our situation is that we have multiple timeseries, for each building and each meter in the building. So, we will be required to modify the code a little bit.\n",
    "\n",
    "Below, we check how many meters exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2380, 2380)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train[['building_id', 'meter']].drop_duplicates()), len(test[['building_id', 'meter']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below has been taken from this stackoverflow answer with some modifications:\n",
    "https://stackoverflow.com/questions/55116638/use-keras-timeseriesgenerator-function-to-generate-squence-group-by-some-id/55118459#55118459\n",
    "\n",
    "The modification is basically that once we subset the data for building ID, it is then subset for meter type also.\n",
    "\n",
    "Further reading about modifying keras generator classes can be found below:\n",
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrdinalEncoder(categories='auto', dtype=<class 'numpy.float64'>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names = ['building_id', 'meter', 'hour', 'dayofweek', 'month']\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit(train[col_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [x+'_cat' for x in col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cat = enc.transform(test[col_names])\n",
    "test['building_id_cat'], test['meter_cat'], test['hour_cat'], test['dayofweek_cat'], test['month_cat'] = np.array(np.asmatrix(test_cat).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/55116638/use-keras-timeseriesgenerator-function-to-generate-squence-group-by-some-id/55118459#55118459\n",
    "# https://keras.io/preprocessing/sequence/\n",
    "# https://stackoverflow.com/questions/49404993/keras-how-to-use-fit-generator-with-multiple-inputs/49405175\n",
    "# https://medium.com/datadriveninvestor/keras-training-on-large-datasets-3e9d9dbc09d4\n",
    "class TSDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, dt, length = 168, batch_size = 10):\n",
    "        self.tgs = list()\n",
    "        self.count = 0 # counter: for verifying the length\n",
    "        # counting batches this way is needed for calculating\n",
    "        # batches for categorical data\n",
    "        \n",
    "        # for each building_id, and meter create batches of time series\n",
    "        for i in range(dt['building_id'].min(),dt['building_id'].max()+1):\n",
    "            sub = dt.loc[dt['building_id'] == i, ['meter', 'meter_reading']]\n",
    "            \n",
    "            for meter in sub['meter'].unique():\n",
    "                # subsetting for meter type\n",
    "                adf = sub.loc[sub['meter'] == meter, 'meter_reading'].values\n",
    "                # the data needs to be reformatted so that it fits the neural \n",
    "                # network model properly\n",
    "                adf = np.reshape(adf, (len(adf),1))\n",
    "                \n",
    "                # adding the timeseriesgenerator to a list of batches\n",
    "                self.tgs.append(TimeseriesGenerator(adf,adf,length,batch_size=batch_size))\n",
    "                \n",
    "                # calculating length\n",
    "                l = np.ceil((len(adf) - length)/batch_size)              \n",
    "                self.count = self.count+l             \n",
    "\n",
    "        self.len = sum([len(tg) for tg in self.tgs])\n",
    "        self.idx_i = list()\n",
    "        self.idx_j = list()\n",
    "\n",
    "        for i, tg in enumerate(self.tgs):\n",
    "            self.idx_i.extend(list(range(len(tg))))\n",
    "            self.idx_j.extend([i]*len(tg))    \n",
    "        #print ( self.idx_i,  self.idx_j)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tgs[self.idx_j[index]][self.idx_i[index]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, dt, length = 168, batch_size = 10):\n",
    "        self.batch_size = batch_size\n",
    "        self.tgs = list()\n",
    "        self.count = 0\n",
    "        col_names = ['building_id', 'meter', 'hour', 'dayofweek', 'month']\n",
    "        for i in range(dt['building_id'].min(),dt['building_id'].max()+1):\n",
    "            sub = dt.loc[dt['building_id'] == i, col_names]\n",
    "            for meter in sub['meter'].unique():\n",
    "                # subsetting the building_id, and meter\n",
    "                adf = sub.loc[sub['meter'] == meter, col_names].copy().reset_index(drop=True)\n",
    "                # number of columns\n",
    "                cols = len(adf.columns)\n",
    "                \n",
    "                # Encoding categorical data\n",
    "                tm = enc.transform(adf[col_names])\n",
    "                tm_short = tm[length:]\n",
    "                \n",
    "                # How many batches \n",
    "                l = np.ceil((len(adf) - length)/batch_size)\n",
    "                self.count = self.count+l\n",
    "                l = int(l)\n",
    "\n",
    "                for j in range(l):\n",
    "                    # correctly indexing the series,\n",
    "                    # this ensures the length is correct\n",
    "                    index_start = j*batch_size\n",
    "                    index_end = index_start+batch_size\n",
    "                    cat = tm_short[index_start:index_end] \n",
    "                    \n",
    "                    # we select the value after the index_end,\n",
    "                    # corresponding to y.\n",
    "                    #val = tm[(index_end+1)] \n",
    "                    size = len(cat)\n",
    "                    #print(val)\n",
    "                    # reshaping the data\n",
    "                    x = cat#.reshape((size,1))\n",
    "                    y = np.zeros((size,1))\n",
    "                    self.tgs.append((x,y))\n",
    "                \n",
    "        self.len = self.count\n",
    "        self.idx_i = list()\n",
    "        self.idx_j = list()\n",
    "\n",
    "        for i, tg in enumerate(self.tgs):\n",
    "            self.idx_i.extend(list(range(len(tg))))\n",
    "            self.idx_j.extend([i]*len(tg))    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.tgs[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleInputGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, dt, length = 168, batch_size = 10):\n",
    "        self.train1_gen = TSDataGenerator(dt,length, batch_size = batch_size)\n",
    "        self.train2_gen = CatDataGenerator(dt,length, batch_size = batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"It is mandatory to implement it on Keras Sequence\"\"\"\n",
    "        if self.train1_gen.__len__() == self.train2_gen.__len__():\n",
    "            return self.train1_gen.__len__()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Getting items from the 2 generators and packing them\"\"\"\n",
    "        X1_batch, Y1_batch = self.train1_gen.__getitem__(index)\n",
    "        X2_batch, Y2_batch = self.train2_gen.__getitem__(index)\n",
    "\n",
    "        X_batch = [X1_batch, X2_batch]\n",
    "\n",
    "        return X_batch, Y1_batch    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on a manual check it was found that there were 12 unique meters in the train_sub dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we want to use 24*7 timesteps, representing 7 days and 24 hours. We can experiment with the batch size but using 20 here for a short example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Validation Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "length = 24*7\n",
    "batch_size = 1024#1024+512\n",
    "train_gen = MultipleInputGenerator(train[train['building_id'].isin(ids_train)],length, batch_size = batch_size)\n",
    "val_gen = MultipleInputGenerator(train[train['building_id'].isin(ids_val)],length, batch_size = batch_size)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the row counts match\n",
    "check = list()\n",
    "for i in range(len(train_gen)):\n",
    "    check.append((train_gen[i][0][1][0][0],train_gen[i][0][1][0][1], train_gen[i][0][0].shape[0]))\n",
    "    if not train_gen[i][0][0].shape[0]==train_gen[i][0][1].shape[0]==train_gen[i][1].shape[0]:\n",
    "        print(train_gen[i][0][0].shape[0],train_gen[i][0][1].shape[0],train_gen[i][1].shape[0], \n",
    "              i, train_gen[i][0][1][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 168, 1) (1024, 5) (1024, 1)\n"
     ]
    }
   ],
   "source": [
    "check = train_gen[0]\n",
    "print(check[0][0].shape, check[0][1].shape, check[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = train[(train['building_id'] == 5) & (train['meter'] == 0) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>386012</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-08 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>388305</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-08 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390597</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-08 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>392891</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-08 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395188</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-08 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2678421</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-19 11:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680488</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-19 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2682557</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-19 13:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2684626</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-19 14:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2686696</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-02-19 15:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1024 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         building_id  meter           timestamp  meter_reading  month  \\\n",
       "386012             5      0 2016-01-08 00:00:00            0.0      1   \n",
       "388305             5      0 2016-01-08 01:00:00            0.0      1   \n",
       "390597             5      0 2016-01-08 02:00:00            0.0      1   \n",
       "392891             5      0 2016-01-08 03:00:00            0.0      1   \n",
       "395188             5      0 2016-01-08 04:00:00            0.0      1   \n",
       "...              ...    ...                 ...            ...    ...   \n",
       "2678421            5      0 2016-02-19 11:00:00            0.0      2   \n",
       "2680488            5      0 2016-02-19 12:00:00            0.0      2   \n",
       "2682557            5      0 2016-02-19 13:00:00            0.0      2   \n",
       "2684626            5      0 2016-02-19 14:00:00            0.0      2   \n",
       "2686696            5      0 2016-02-19 15:00:00            0.0      2   \n",
       "\n",
       "         dayofweek  hour  \n",
       "386012           4     0  \n",
       "388305           4     1  \n",
       "390597           4     2  \n",
       "392891           4     3  \n",
       "395188           4     4  \n",
       "...            ...   ...  \n",
       "2678421          4    11  \n",
       "2680488          4    12  \n",
       "2682557          4    13  \n",
       "2684626          4    14  \n",
       "2686696          4    15  \n",
       "\n",
       "[1024 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[length:(length+batch_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function - Root Mean Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1, 168)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(batch_size,1,length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#model = Sequential()\n",
    "filters = 10\n",
    "ncols = len(col_names) # categorical columns\n",
    "states = 20\n",
    "act = 'linear'\n",
    "\n",
    "input_shape1 = Input(shape=(length,1))\n",
    "input_shape2 = Input(shape=(ncols,))\n",
    "\n",
    "n_a = LSTM(states, return_sequences=True)(input_shape1)\n",
    "n_a = Lambda(lambda x: keras.backend.mean(x, axis=2))(n_a)\n",
    "n_a = Model(inputs=input_shape1, outputs=n_a)\n",
    "\n",
    "n1 = Dense(5, activation=act)(input_shape2)\n",
    "n1 = Model(inputs=input_shape2, output=n1)\n",
    "\n",
    "combined2 = keras.layers.concatenate([n_a.output, n1.output])\n",
    "out2 = Dense(states, activation=act)(combined2)#Dense(states, activation=act)(combined2)\n",
    "out2 = LeakyReLU(alpha=0.1)(out2)\n",
    "out2 = Dropout(0.2)(out2)\n",
    "out2 = Dense(1)(out2)#Dense(1, activation=act)(out2)\n",
    "\n",
    "model2 = Model(inputs = [input_shape1, input_shape2], outputs = out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(clipnorm=1.)\n",
    "\n",
    "model2.compile(loss=root_mean_squared_error, optimizer=opt, metrics=['mse', 'mae', 'mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 168, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 168, 20)      1760        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 168)          0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            30          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 173)          0           lambda_1[0][0]                   \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 20)           3480        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 20)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 20)           0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            21          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,291\n",
      "Trainable params: 5,291\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train['meter_reading'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "719/719 [==============================] - 165s 229ms/step - loss: 2.3171 - mse: 53.6629 - mae: 1.8528 - mape: 242276176.0000 - val_loss: 0.3267 - val_mse: 0.0209 - val_mae: 0.1178 - val_mape: 26406794.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f265ada7908>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model on dataset\n",
    "epochs = 1 #TODO: change it back to 5\n",
    "model2.fit_generator(generator=train_gen,\n",
    "                    validation_data=val_gen, epochs=1, \n",
    "                    use_multiprocessing=True, workers = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Function for Prediction - Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test[(test['building_id'] == 0) & (test['meter'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_grouped = sub.groupby(['building_id', 'meter'])\n",
    "train_grouped = train.groupby(['building_id', 'meter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = ['row_id', 'building_id', 'meter', 'timestamp', 'meter_reading']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = train.groupby(['building_id', 'meter'])['meter_reading'].apply(lambda x: pd.Series(x.tail(168).values)).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old_sub= np.array(old.loc[[0,0]][range(168)])\n",
    "#old_sub.reshape((1, old_sub.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(group):\n",
    "    group_name = group.name\n",
    "    print(group_name)\n",
    "    \n",
    "    global old\n",
    "    old_sub= np.array(old.loc[list(group_name)][range(168)])[0]\n",
    "    #print(old_sub)\n",
    "        \n",
    "    for i, row in group.iterrows():      \n",
    "        X_test = old_sub\n",
    "        val_count = X_test.shape[0]\n",
    "        X_test = X_test.reshape((1, val_count, 1))\n",
    "        r_cat = np.array(row[new_cols]).reshape(1, -1)\n",
    "        \n",
    "        test_input = [X_test, r_cat]        \n",
    "        result=model2.predict(test_input)\n",
    "        \n",
    "        new = result[0]\n",
    "        old_sub = np.concatenate([old_sub[1:], new])\n",
    "        #print(new)\n",
    "        \n",
    "        row['meter_reading'] = new[0]\n",
    "        result_rows.append(row[['row_id', 'meter_reading']].to_dict())\n",
    "        \n",
    "    print(r_cat)\n",
    "    return \"Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ddf = dd.from_pandas(test, npartitions=10)\n",
    "#ddf = ddf.set_index('building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_rows = list()\n",
    "#ddf.groupby(['building_id', 'meter']).apply(predict, meta=object).compute()\n",
    "#ddf.map_partitions(predict, meta=object).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old_sub[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#result_rows = list()\n",
    "#test_grouped.apply(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = pd.DataFrame(result_rows)\n",
    "#result.to_csv('result.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Function for Prediction - Method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New strategy:\n",
    "1. Transpose the old dataframe, such that the indices are 168 timestamps, and each column is a building_id, meter combination.\n",
    "2. Similarly, transpose the test data.\n",
    "3. Now, iterate through timesteps.\n",
    "4. For each time step, create batch of 2803 inputs of shape(1, 168) (or whatever the total combination of building id, meters is)\n",
    "5. Form categorical inputs using the timestamp indices and the column labels.\n",
    "6. The final input shape should be (2803, 168, 1) and (2803, 1, 5).\n",
    "7. The inputs are fed to obtain the predict.\n",
    "8. The inputs are appended to the initial old table, and the 168 values from the bottom are taken again, and the steps are repeated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_T = old.T#.loc[:,[0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = test[['timestamp','hour_cat','dayofweek_cat','month_cat']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old_T.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old_T.columns.to_frame().reset_index(drop = True).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from int to timestamp\n",
    "#datetime.fromtimestamp(row['timestamp'].value/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>hour_cat</th>\n",
       "      <th>dayofweek_cat</th>\n",
       "      <th>month_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41697595</td>\n",
       "      <td>1444</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-09 07:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41697596</td>\n",
       "      <td>1445</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-09 07:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41697597</td>\n",
       "      <td>1446</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-09 07:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41697598</td>\n",
       "      <td>1447</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-09 07:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41697599</td>\n",
       "      <td>1448</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-05-09 07:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41697600 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          building_id  meter           timestamp  hour_cat  dayofweek_cat  \\\n",
       "0                   0      0 2017-01-01 00:00:00       0.0            6.0   \n",
       "1                   1      0 2017-01-01 00:00:00       0.0            6.0   \n",
       "2                   2      0 2017-01-01 00:00:00       0.0            6.0   \n",
       "3                   3      0 2017-01-01 00:00:00       0.0            6.0   \n",
       "4                   4      0 2017-01-01 00:00:00       0.0            6.0   \n",
       "...               ...    ...                 ...       ...            ...   \n",
       "41697595         1444      0 2018-05-09 07:00:00       7.0            2.0   \n",
       "41697596         1445      0 2018-05-09 07:00:00       7.0            2.0   \n",
       "41697597         1446      0 2018-05-09 07:00:00       7.0            2.0   \n",
       "41697598         1447      0 2018-05-09 07:00:00       7.0            2.0   \n",
       "41697599         1448      0 2018-05-09 07:00:00       7.0            2.0   \n",
       "\n",
       "          month_cat  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "...             ...  \n",
       "41697595        4.0  \n",
       "41697596        4.0  \n",
       "41697597        4.0  \n",
       "41697598        4.0  \n",
       "41697599        4.0  \n",
       "\n",
       "[41697600 rows x 6 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[['building_id', 'meter','timestamp','hour_cat','dayofweek_cat','month_cat']].drop_dpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-2ca5072202b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtest_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_cat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "result_list = list()\n",
    "values = np.array([0])\n",
    "\n",
    "for i, row in new.iterrows():\n",
    "    #i = 0\n",
    "    #row = new.iloc[0]\n",
    "\n",
    "    r_cat = row[['hour_cat', 'dayofweek_cat', 'month_cat']]\n",
    "    r_cat = np.array([np.concatenate([np.array(x), np.array(r_cat)]) for x in old_T.columns])\n",
    "\n",
    "    shape = old.values.shape\n",
    "    \n",
    "    if result_list == list():\n",
    "        X_test = np.reshape(old.values, (shape[0], shape[1], 1))\n",
    "    else:\n",
    "        X_test = np.reshape(values, (shape[0], shape[1], 1))\n",
    "    \n",
    "    test_input = [X_test, r_cat]   \n",
    "    result=model2.predict(test_input)\n",
    "\n",
    "    values = np.concatenate([old.values, result], axis = 1)[:,1:]\n",
    "    result_list.append(np.concatenate([r_cat, result], axis = 1))\n",
    "    \n",
    "    result = pd.DataFrame(np.concatenate(result_list), columns = ['building_id', 'meter', 'hour_cat', \n",
    "                                                              'dayofweek_cat', 'month_cat', 'meter_reading',])\n",
    "    result.to_csv(str(row['timestamp'].value) + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = pd.DataFrame(np.concatenate(result_list), columns = ['building_id', 'meter', 'hour_cat', \n",
    "#                                                               'dayofweek_cat', 'month_cat', 'meter_reading',])\n",
    "# result.to_csv('result.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>hour_cat</th>\n",
       "      <th>dayofweek_cat</th>\n",
       "      <th>month_cat</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.329748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  building_id meter hour_cat dayofweek_cat month_cat meter_reading\n",
       "0           0     0        0             6         0      0.329748\n",
       "1           1     0        0             6         0      0.307844\n",
       "2           2     0        0             6         0      0.228884"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Function for Prediction - Method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "old = train.groupby(['building_id', 'meter'])['meter_reading'].apply(lambda x: pd.Series(x.tail(168).values)).unstack()\n",
    "check_grp = test.groupby('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (168, 41697600) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-cf1f2da770ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Joining old and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_old_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'building_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mddf_test_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_old_merged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'building_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'meter'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     )\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mllabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         )\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   2052\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2053\u001b[0m             b = make_block(\n\u001b[0;32m-> 2054\u001b[0;31m                 \u001b[0mconcatenate_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2055\u001b[0m                 \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m    251\u001b[0m     to_concat = [\n\u001b[1;32m    252\u001b[0m         \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     ]\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m     to_concat = [\n\u001b[1;32m    252\u001b[0m         \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     ]\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[0;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"F\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m     func = _get_take_nd_function(\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate array with shape (168, 41697600) and data type float64"
     ]
    }
   ],
   "source": [
    "# def predict2(df):\n",
    "#     old = df.groupby(['building_id', 'meter'])['meter_reading'].apply(lambda x: pd.Series(x.head(168).values)).unstack()\n",
    "#     group = df.groupby(['building_id', 'meter'].\n",
    "# # Joining old and test data\n",
    "# test_old_append = train.groupby(['building_id', 'meter']).tail(168).reset_index().append(test)\n",
    "# ddf_test_old = dd.from_pandas(test_old_merged)\n",
    "# df = df.set_index('building_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-01 00:00:00\n",
      "2017-01-01 01:00:00\n",
      "2017-01-01 02:00:00\n",
      "2017-01-01 03:00:00\n",
      "2017-01-01 04:00:00\n",
      "2017-01-01 05:00:00\n",
      "2017-01-01 06:00:00\n",
      "2017-01-01 07:00:00\n",
      "2017-01-01 08:00:00\n",
      "2017-01-01 09:00:00\n",
      "2017-01-01 10:00:00\n",
      "2017-01-01 11:00:00\n",
      "2017-01-01 12:00:00\n",
      "2017-01-01 13:00:00\n",
      "2017-01-01 14:00:00\n",
      "2017-01-01 15:00:00\n",
      "2017-01-01 16:00:00\n",
      "2017-01-01 17:00:00\n",
      "2017-01-01 18:00:00\n",
      "2017-01-01 19:00:00\n",
      "2017-01-01 20:00:00\n",
      "2017-01-01 21:00:00\n",
      "2017-01-01 22:00:00\n",
      "2017-01-01 23:00:00\n",
      "2017-01-02 00:00:00\n",
      "2017-01-02 01:00:00\n",
      "2017-01-02 02:00:00\n",
      "2017-01-02 03:00:00\n",
      "2017-01-02 04:00:00\n",
      "2017-01-02 05:00:00\n",
      "2017-01-02 06:00:00\n",
      "2017-01-02 07:00:00\n",
      "2017-01-02 08:00:00\n",
      "2017-01-02 09:00:00\n",
      "2017-01-02 10:00:00\n",
      "2017-01-02 11:00:00\n",
      "2017-01-02 12:00:00\n",
      "2017-01-02 13:00:00\n",
      "2017-01-02 14:00:00\n",
      "2017-01-02 15:00:00\n",
      "2017-01-02 16:00:00\n",
      "2017-01-02 17:00:00\n",
      "2017-01-02 18:00:00\n",
      "2017-01-02 19:00:00\n",
      "2017-01-02 20:00:00\n",
      "2017-01-02 21:00:00\n",
      "2017-01-02 22:00:00\n",
      "2017-01-02 23:00:00\n",
      "2017-01-03 00:00:00\n",
      "2017-01-03 01:00:00\n",
      "2017-01-03 02:00:00\n",
      "2017-01-03 03:00:00\n",
      "2017-01-03 04:00:00\n",
      "2017-01-03 05:00:00\n",
      "2017-01-03 06:00:00\n",
      "2017-01-03 07:00:00\n",
      "2017-01-03 08:00:00\n",
      "2017-01-03 09:00:00\n",
      "2017-01-03 10:00:00\n",
      "2017-01-03 11:00:00\n",
      "2017-01-03 12:00:00\n",
      "2017-01-03 13:00:00\n",
      "2017-01-03 14:00:00\n",
      "2017-01-03 15:00:00\n",
      "2017-01-03 16:00:00\n",
      "2017-01-03 17:00:00\n",
      "2017-01-03 18:00:00\n",
      "2017-01-03 19:00:00\n",
      "2017-01-03 20:00:00\n",
      "2017-01-03 21:00:00\n",
      "2017-01-03 22:00:00\n",
      "2017-01-03 23:00:00\n",
      "2017-01-04 00:00:00\n",
      "2017-01-04 01:00:00\n",
      "2017-01-04 02:00:00\n",
      "2017-01-04 03:00:00\n",
      "2017-01-04 04:00:00\n",
      "2017-01-04 05:00:00\n",
      "2017-01-04 06:00:00\n",
      "2017-01-04 07:00:00\n",
      "2017-01-04 08:00:00\n",
      "2017-01-04 09:00:00\n",
      "2017-01-04 10:00:00\n",
      "2017-01-04 11:00:00\n",
      "2017-01-04 12:00:00\n",
      "2017-01-04 13:00:00\n",
      "2017-01-04 14:00:00\n",
      "2017-01-04 15:00:00\n",
      "2017-01-04 16:00:00\n",
      "2017-01-04 17:00:00\n",
      "2017-01-04 18:00:00\n",
      "2017-01-04 19:00:00\n",
      "2017-01-04 20:00:00\n",
      "2017-01-04 21:00:00\n",
      "2017-01-04 22:00:00\n",
      "2017-01-04 23:00:00\n",
      "2017-01-05 00:00:00\n",
      "2017-01-05 01:00:00\n",
      "2017-01-05 02:00:00\n",
      "2017-01-05 03:00:00\n",
      "2017-01-05 04:00:00\n",
      "2017-01-05 05:00:00\n",
      "2017-01-05 06:00:00\n",
      "2017-01-05 07:00:00\n",
      "2017-01-05 08:00:00\n",
      "2017-01-05 09:00:00\n",
      "2017-01-05 10:00:00\n",
      "2017-01-05 11:00:00\n",
      "2017-01-05 12:00:00\n",
      "2017-01-05 13:00:00\n",
      "2017-01-05 14:00:00\n",
      "2017-01-05 15:00:00\n",
      "2017-01-05 16:00:00\n",
      "2017-01-05 17:00:00\n",
      "2017-01-05 18:00:00\n",
      "2017-01-05 19:00:00\n",
      "2017-01-05 20:00:00\n",
      "2017-01-05 21:00:00\n",
      "2017-01-05 22:00:00\n",
      "2017-01-05 23:00:00\n",
      "2017-01-06 00:00:00\n",
      "2017-01-06 01:00:00\n",
      "2017-01-06 02:00:00\n",
      "2017-01-06 03:00:00\n",
      "2017-01-06 04:00:00\n",
      "2017-01-06 05:00:00\n",
      "2017-01-06 06:00:00\n",
      "2017-01-06 07:00:00\n",
      "2017-01-06 08:00:00\n",
      "2017-01-06 09:00:00\n",
      "2017-01-06 10:00:00\n",
      "2017-01-06 11:00:00\n",
      "2017-01-06 12:00:00\n",
      "2017-01-06 13:00:00\n",
      "2017-01-06 14:00:00\n",
      "2017-01-06 15:00:00\n",
      "2017-01-06 16:00:00\n",
      "2017-01-06 17:00:00\n",
      "2017-01-06 18:00:00\n",
      "2017-01-06 19:00:00\n",
      "2017-01-06 20:00:00\n",
      "2017-01-06 21:00:00\n",
      "2017-01-06 22:00:00\n",
      "2017-01-06 23:00:00\n",
      "2017-01-07 00:00:00\n",
      "2017-01-07 01:00:00\n",
      "2017-01-07 02:00:00\n",
      "2017-01-07 03:00:00\n",
      "2017-01-07 04:00:00\n",
      "2017-01-07 05:00:00\n",
      "2017-01-07 06:00:00\n",
      "2017-01-07 07:00:00\n",
      "2017-01-07 08:00:00\n",
      "2017-01-07 09:00:00\n",
      "2017-01-07 10:00:00\n",
      "2017-01-07 11:00:00\n",
      "2017-01-07 12:00:00\n",
      "2017-01-07 13:00:00\n",
      "2017-01-07 14:00:00\n",
      "2017-01-07 15:00:00\n",
      "2017-01-07 16:00:00\n",
      "2017-01-07 17:00:00\n",
      "2017-01-07 18:00:00\n",
      "2017-01-07 19:00:00\n",
      "2017-01-07 20:00:00\n",
      "2017-01-07 21:00:00\n",
      "2017-01-07 22:00:00\n",
      "2017-01-07 23:00:00\n",
      "2017-01-08 00:00:00\n",
      "2017-01-08 01:00:00\n",
      "2017-01-08 02:00:00\n",
      "2017-01-08 03:00:00\n",
      "2017-01-08 04:00:00\n",
      "2017-01-08 05:00:00\n",
      "2017-01-08 06:00:00\n",
      "2017-01-08 07:00:00\n",
      "2017-01-08 08:00:00\n",
      "2017-01-08 09:00:00\n",
      "2017-01-08 10:00:00\n",
      "2017-01-08 11:00:00\n",
      "2017-01-08 12:00:00\n",
      "2017-01-08 13:00:00\n",
      "2017-01-08 14:00:00\n",
      "2017-01-08 15:00:00\n",
      "2017-01-08 16:00:00\n",
      "2017-01-08 17:00:00\n",
      "2017-01-08 18:00:00\n",
      "2017-01-08 19:00:00\n",
      "2017-01-08 20:00:00\n",
      "2017-01-08 21:00:00\n",
      "2017-01-08 22:00:00\n",
      "2017-01-08 23:00:00\n",
      "2017-01-09 00:00:00\n",
      "2017-01-09 01:00:00\n",
      "2017-01-09 02:00:00\n",
      "2017-01-09 03:00:00\n",
      "2017-01-09 04:00:00\n",
      "2017-01-09 05:00:00\n",
      "2017-01-09 06:00:00\n",
      "2017-01-09 07:00:00\n",
      "2017-01-09 08:00:00\n",
      "2017-01-09 09:00:00\n",
      "2017-01-09 10:00:00\n",
      "2017-01-09 11:00:00\n",
      "2017-01-09 12:00:00\n",
      "2017-01-09 13:00:00\n",
      "2017-01-09 14:00:00\n",
      "2017-01-09 15:00:00\n",
      "2017-01-09 16:00:00\n",
      "2017-01-09 17:00:00\n",
      "2017-01-09 18:00:00\n",
      "2017-01-09 19:00:00\n",
      "2017-01-09 20:00:00\n",
      "2017-01-09 21:00:00\n",
      "2017-01-09 22:00:00\n",
      "2017-01-09 23:00:00\n",
      "2017-01-10 00:00:00\n",
      "2017-01-10 01:00:00\n",
      "2017-01-10 02:00:00\n",
      "2017-01-10 03:00:00\n",
      "2017-01-10 04:00:00\n",
      "2017-01-10 05:00:00\n",
      "2017-01-10 06:00:00\n",
      "2017-01-10 07:00:00\n",
      "2017-01-10 08:00:00\n",
      "2017-01-10 09:00:00\n",
      "2017-01-10 10:00:00\n",
      "2017-01-10 11:00:00\n",
      "2017-01-10 12:00:00\n",
      "2017-01-10 13:00:00\n",
      "2017-01-10 14:00:00\n",
      "2017-01-10 15:00:00\n",
      "2017-01-10 16:00:00\n",
      "2017-01-10 17:00:00\n",
      "2017-01-10 18:00:00\n",
      "2017-01-10 19:00:00\n",
      "2017-01-10 20:00:00\n",
      "2017-01-10 21:00:00\n",
      "2017-01-10 22:00:00\n",
      "2017-01-10 23:00:00\n",
      "2017-01-11 00:00:00\n",
      "2017-01-11 01:00:00\n",
      "2017-01-11 02:00:00\n",
      "2017-01-11 03:00:00\n",
      "2017-01-11 04:00:00\n",
      "2017-01-11 05:00:00\n",
      "2017-01-11 06:00:00\n",
      "2017-01-11 07:00:00\n",
      "2017-01-11 08:00:00\n",
      "2017-01-11 09:00:00\n",
      "2017-01-11 10:00:00\n",
      "2017-01-11 11:00:00\n",
      "2017-01-11 12:00:00\n",
      "2017-01-11 13:00:00\n",
      "2017-01-11 14:00:00\n",
      "2017-01-11 15:00:00\n",
      "2017-01-11 16:00:00\n",
      "2017-01-11 17:00:00\n",
      "2017-01-11 18:00:00\n",
      "2017-01-11 19:00:00\n",
      "2017-01-11 20:00:00\n",
      "2017-01-11 21:00:00\n",
      "2017-01-11 22:00:00\n",
      "2017-01-11 23:00:00\n",
      "2017-01-12 00:00:00\n",
      "2017-01-12 01:00:00\n",
      "2017-01-12 02:00:00\n",
      "2017-01-12 03:00:00\n",
      "2017-01-12 04:00:00\n",
      "2017-01-12 05:00:00\n",
      "2017-01-12 06:00:00\n",
      "2017-01-12 07:00:00\n",
      "2017-01-12 08:00:00\n",
      "2017-01-12 09:00:00\n",
      "2017-01-12 10:00:00\n",
      "2017-01-12 11:00:00\n",
      "2017-01-12 12:00:00\n",
      "2017-01-12 13:00:00\n",
      "2017-01-12 14:00:00\n",
      "2017-01-12 15:00:00\n",
      "2017-01-12 16:00:00\n",
      "2017-01-12 17:00:00\n",
      "2017-01-12 18:00:00\n",
      "2017-01-12 19:00:00\n",
      "2017-01-12 20:00:00\n",
      "2017-01-12 21:00:00\n",
      "2017-01-12 22:00:00\n",
      "2017-01-12 23:00:00\n",
      "2017-01-13 00:00:00\n",
      "2017-01-13 01:00:00\n",
      "2017-01-13 02:00:00\n",
      "2017-01-13 03:00:00\n",
      "2017-01-13 04:00:00\n",
      "2017-01-13 05:00:00\n",
      "2017-01-13 06:00:00\n",
      "2017-01-13 07:00:00\n",
      "2017-01-13 08:00:00\n",
      "2017-01-13 09:00:00\n",
      "2017-01-13 10:00:00\n",
      "2017-01-13 11:00:00\n",
      "2017-01-13 12:00:00\n",
      "2017-01-13 13:00:00\n",
      "2017-01-13 14:00:00\n",
      "2017-01-13 15:00:00\n",
      "2017-01-13 16:00:00\n",
      "2017-01-13 17:00:00\n",
      "2017-01-13 18:00:00\n",
      "2017-01-13 19:00:00\n",
      "2017-01-13 20:00:00\n",
      "2017-01-13 21:00:00\n",
      "2017-01-13 22:00:00\n",
      "2017-01-13 23:00:00\n",
      "2017-01-14 00:00:00\n",
      "2017-01-14 01:00:00\n",
      "2017-01-14 02:00:00\n",
      "2017-01-14 03:00:00\n",
      "2017-01-14 04:00:00\n",
      "2017-01-14 05:00:00\n",
      "2017-01-14 06:00:00\n",
      "2017-01-14 07:00:00\n",
      "2017-01-14 08:00:00\n",
      "2017-01-14 09:00:00\n",
      "2017-01-14 10:00:00\n",
      "2017-01-14 11:00:00\n",
      "2017-01-14 12:00:00\n",
      "2017-01-14 13:00:00\n",
      "2017-01-14 14:00:00\n",
      "2017-01-14 15:00:00\n",
      "2017-01-14 16:00:00\n",
      "2017-01-14 17:00:00\n",
      "2017-01-14 18:00:00\n",
      "2017-01-14 19:00:00\n",
      "2017-01-14 20:00:00\n",
      "2017-01-14 21:00:00\n",
      "2017-01-14 22:00:00\n",
      "2017-01-14 23:00:00\n",
      "2017-01-15 00:00:00\n",
      "2017-01-15 01:00:00\n",
      "2017-01-15 02:00:00\n",
      "2017-01-15 03:00:00\n"
     ]
    }
   ],
   "source": [
    "jdf_cols = {a: a-1 for a in range(length+1)}\n",
    "first = True\n",
    "\n",
    "for name, group in check_grp:\n",
    "    if first==True:\n",
    "        jdf = pd.merge(group, old, left_on=['building_id', 'meter'], right_on=['building_id', 'meter'], how='inner')\n",
    "        test_result = jdf\n",
    "        first = False\n",
    "    \n",
    "    X_test = np.reshape(np.array(jdf[range(0,168)]), (2380, 168,1))\n",
    "    r_cat = np.array(jdf[new_cols])\n",
    "    \n",
    "    test_input = [X_test, r_cat] \n",
    "    \n",
    "    result=model2.predict(test_input)\n",
    "    jdf[168] = result.reshape(len(result),)\n",
    "    test_result[name] = result.reshape(len(result),)\n",
    "    \n",
    "    jdf[range(1,169)].rename(jdf_cols, axis=1)\n",
    "    \n",
    "    print(name)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result.to_csv('test_result.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN 1-D + LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Sequential()\n",
    "filters = 10\n",
    "ncols = len(col_names) # categorical columns\n",
    "states = 24\n",
    "input_shape1 = Input(shape=(length,1))\n",
    "input_shape2 = Input(shape=(ncols,))\n",
    "\n",
    "m1 = Conv1D(filters=filters, kernel_size=7, activation='relu')(input_shape1)\n",
    "m1 = MaxPooling1D(pool_size=2, strides=2)(m1)\n",
    "\n",
    "#m2 = Conv1D(filters=filters, kernel_size=5, activation='relu')(input_shape1)\n",
    "#m2 = MaxPooling1D(pool_size=2, strides=2)(m2)\n",
    "\n",
    "#m3 = Conv1D(filters=filters, kernel_size=7, activation='relu')(input_shape1)\n",
    "#m3 = MaxPooling1D(pool_size=2, strides=2)(m3)\n",
    "\n",
    "#m = keras.layers.concatenate([m1, m2, m3], axis = 1)\n",
    "#m = Reshape((246,filters))(m)\n",
    "m_a = LSTM(states, return_sequences=True)(m1)\n",
    "m_a = Lambda(lambda x: keras.backend.mean(x, axis=2))(m_a)\n",
    "m_a = Model(inputs=input_shape1, outputs=m_a)\n",
    "\n",
    "#m_b = Dense(2, activation='relu')(input_shape2)\n",
    "#m_b = Model(inputs=input_shape2, outputs=m_b)\n",
    "\n",
    "#combined = keras.layers.concatenate([m_a.output, m_b.output])\n",
    "combined = keras.layers.concatenate([m_a.output, input_shape2])\n",
    "\n",
    "out = Dense(states, activation='relu')(combined)\n",
    "out = Dense(1, activation='relu')(out)\n",
    "\n",
    "model = Model(inputs = [input_shape1, input_shape2], outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=root_mean_squared_error, optimizer='rmsprop', metrics=['mse', 'mae', 'mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 519s - loss: nan - mse: nan - mae: nan - mape: nan - val_loss: nan - val_mse: nan - val_mae: nan - val_mape: nan\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-41:\n",
      "Process ForkPoolWorker-43:\n",
      "Process ForkPoolWorker-44:\n",
      "Process ForkPoolWorker-38:\n",
      "Process ForkPoolWorker-45:\n",
      "Process ForkPoolWorker-35:\n",
      "Process ForkPoolWorker-29:\n",
      "Process ForkPoolWorker-46:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-48:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-30:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-42:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-33:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-40:\n",
      "Process ForkPoolWorker-36:\n",
      "Process ForkPoolWorker-37:\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-34:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-47:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-26:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process ForkPoolWorker-32:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Process ForkPoolWorker-39:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Process ForkPoolWorker-28:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Process ForkPoolWorker-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 343, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-0278748c947b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     workers=12, verbose =2)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Add input for building id, and join it with lamda output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model on dataset\n",
    "model.fit_generator(generator=train_gen,\n",
    "                    validation_data=val_gen, epochs=5,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=12, verbose =2)\n",
    "# Add input for building id, and join it with lamda output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
